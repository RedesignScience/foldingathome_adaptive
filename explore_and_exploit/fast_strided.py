import multiprocessing
import numpy as np
from glob import glob
import mdtraj as md
from simtk import openmm
from simtk.openmm import app
import os
import pyemma
import bz2

n_procs = 16
n_seeds = 50
stride = 10

# if you change these, you have to rm features.npy and recompute
#select_contacts = np.load('select_contacts.npy')

def calc_features(traj, stride=stride):
    # remove 'positions.xtc' from path
    path = traj[:-13] + 'features.npy'
    if os.path.exists(path):
        return np.load(path, allow_pickle=True)[::stride]
    else:
        traj = md.load(traj, top='top.pdb')
        contacts = md.compute_contacts(traj)[0]
        #contacts = md.compute_contacts(traj, contacts=select_contacts)[0]
        features = contacts
        path_split = path.split('/')
        np.save(f'temp/{path_split[-4]}_{path_split[-3]}_{path_split[-2]}_{path_split[-1]}', features)
        os.system(f'sudo mv temp/{path_split[-4]}_{path_split[-3]}_{path_split[-2]}_{path_split[-1]} {path}')
    return features[::stride]

def calc_msm_counts(features):
    # stride 10 (set in calc_features) so lag time is 1 (with 0.1 ns/frame those are both 1ns)
    tica = pyemma.coordinates.tica(features, lag=1, dim=5, kinetic_map=True, commute_map=False)
    tica_projection = tica.get_output()
    if len(np.concatenate(tica_projection)) > 100:
        kmeans = pyemma.coordinates.cluster_kmeans(tica_projection, k=100, max_iter=1000, n_jobs=1)
    else: # for beginning of sampling
        kmeans = pyemma.coordinates.cluster_kmeans(tica_projection, k=10, max_iter=1000, n_jobs=1)
    dtrajs = kmeans.dtrajs
    counts = np.bincount(np.concatenate(dtrajs))
    return counts, dtrajs

def draw_seeds(goals, counts, dtrajs, n_seeds, explore_weight=0.5, truncate_prob=True, max_states=None):
    indexes = []
    for i,traj in enumerate(goals):
        for j,frame in enumerate(traj):
            indexes.append([i,j])
    indexes = np.array(indexes)

    goals = np.concatenate(goals)
    dtrajs = np.concatenate(dtrajs)
    
    goal_scores = []
    for state in range(len(set(dtrajs))):
        goal = np.mean(goals[np.argwhere(dtrajs == state).flatten()])
        goal_scores.append(goal)
    # normalize to [0,1]
    goal_scores = (goal_scores - np.min(goal_scores)) / (np.max(goal_scores) - np.min(goal_scores))

    count_scores = 1/counts
    # normalize to [0,1] (if all counts the same, set to uniform)
    if np.max(count_scores) - np.min(count_scores) == 0:
        count_scores = np.ones(len(count_scores)) / len(count_scores)
    else:
        count_scores = (count_scores - np.min(count_scores)) / (np.max(count_scores) - np.min(count_scores))

    combo_scores = (1-explore_weight)*goal_scores + explore_weight*count_scores
    if truncate_prob: # using the cumsum method from htmd
        order = np.argsort(combo_scores)[::-1]
        combo_scores_sorted = combo_scores[order]
        truncate_bool = (n_seeds * combo_scores_sorted / np.cumsum(combo_scores_sorted)) < 1
        if not max_states:
            combo_scores[order[truncate_bool]] = 0
        else:
            if len(truncate_bool) - sum(truncate_bool) > max_states:
                combo_scores[order[max_states:]] = 0
            else:
                combo_scores[order[truncate_bool]] = 0
    # normalize to sum 1
    combo_scores = combo_scores / np.sum(combo_scores)
    
    # draw states
    states_drawn = np.random.choice(range(len(set(dtrajs))), n_seeds, replace=True, p=combo_scores)
    
    # randomly draw frames from those states
    seeds = []
    for state in states_drawn:
        indexes_ = indexes[np.argwhere(dtrajs == state).flatten()]
        seeds_ = np.random.choice(range(len(indexes_)), 1)
        seeds_ = indexes_[seeds_]
        seeds.append(seeds_)
    seeds = np.concatenate(seeds)

    return seeds
    
def make_seed(trajs, index, i, stride=stride):

    seed = md.load(trajs[index[0]], top='top.pdb')[index[1]*stride]
    seed.save('seeds_pdb/%d.pdb' % i)
    box_vectors = seed.openmm_boxes(0)

    pdb = app.PDBFile('seeds_pdb/%d.pdb' % i)
    
    with open('system.xml', 'r') as infile:
        system = openmm.XmlSerializer.deserialize(infile.read())

    with open('integrator.xml', 'r') as infile:
        integrator = openmm.XmlSerializer.deserialize(infile.read())

    context = openmm.Context(system, integrator)

    context.setPeriodicBoxVectors(*box_vectors)
    context.setPositions(pdb.positions)
    context.setVelocitiesToTemperature(310)
    context.applyConstraints(integrator.getConstraintTolerance())
    context.applyVelocityConstraints(integrator.getConstraintTolerance())

    state = context.getState(getPositions=True, getVelocities=True, getEnergy=True, getForces=True)

    with bz2.open('SEEDS/%d.xml.bz2' % i, 'wt') as outfile:
        xml = openmm.XmlSerializer.serialize(state)
        outfile.write(xml)

def main():

    trajs = sorted(glob('/home/server/server2/data/SVR3476416914/PROJ17805/RUN*/CLONE*/results*/positions.xtc'))
    
    features = pool.map(calc_features, trajs)
    # to speed up tica let's take random 1000 features
    choice = np.random.choice(range(features[0].shape[1]), 1000)
    counts, dtrajs = calc_msm_counts([x[:,choice] for x in features])
    # save dtrajs for checking progress
    np.save('current_dtrajs.npy', dtrajs)
    np.save('current_trajs_glob.npy', trajs)
    # using one distance between first-to-come-out-in-activation helix and core -- btw residues (0-index) 116 and 177 (both alanines, so no side chain weirdness as distances are closest heavy atom)
    goals = [x[:,15312] for x in features]

    with open('current_goal.txt', 'w') as f:
        f.write('Current max. goal: %f' % np.max(np.concatenate(goals)))
        f.write('\n')

    # default FAST -- set explore_weight=0.5
    seeds = draw_seeds(goals, counts, dtrajs, n_seeds, explore_weight=0.5, truncate_prob=True)

    pool.starmap(make_seed, [(trajs, seeds[i], i) for i in range(len(seeds))])

    os.system('sudo cp -r SEEDS /home/server/server2/projects/17805/')

if __name__ == "__main__":
    pool = multiprocessing.Pool(n_procs)
    while True:
        main()

